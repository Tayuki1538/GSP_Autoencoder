{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "743c7118-2559-4446-a710-7260eb6276a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6213bb9-fb8d-404e-9dc4-c04a2d710354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pyroomacoustics as pra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from data_loader.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e77df868-88a8-4f98-90c3-e397d1b6173d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82a8fdcb-f415-42d6-9462-a3f4669c2e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.directivities import (\n",
    "    DirectivityPattern,\n",
    "    DirectionVector,\n",
    "    CardioidFamily,\n",
    ")\n",
    "dir_obj = CardioidFamily(\n",
    "    orientation=DirectionVector(azimuth=0, colatitude=180, degrees=True),\n",
    "    pattern_enum=DirectivityPattern.HYPERCARDIOID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c39b559-f7bb-418f-8581-1b2ad4eae47a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 学習データの作成\n",
    "\n",
    "'''\n",
    "測位領域：3m x 4m\n",
    "データ数1000: 30 x 40 = 1200(10cmおき)\n",
    "データ数10000: 117 x 157 = 18369(2.5cmおき)\n",
    "データ数100000: 293 x 393 = 115149(1cmおき)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "671ea7f7-387a-438e-b6ec-725e72312836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## channel: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c6c9c36-bc17-49c8-a56e-6107c4fdd194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 測位用(5cmおき: データ数4941)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "\n",
    "mic_loc = np.array([[], [], []])\n",
    "\n",
    "for i in range(61*81):\n",
    "    mic_loc = np.c_[mic_loc, [(i//61)/20 + 4.6, (i%61)/20 + 0.4, 1]]\n",
    "    \n",
    "room.add_microphone(mic_loc)\n",
    "\n",
    "_, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "# 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "# オプションで delay を追加することもできます。\n",
    "room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "# S/N 比\n",
    "SNR = 5\n",
    "\n",
    "#シミュレーション\n",
    "room.simulate(SNR)\n",
    "\n",
    "simulation_data = room.mic_array.signals\n",
    "\n",
    "for i in range(simulation_data.shape[0]):\n",
    "    \n",
    "    X = simulation_data[i]\n",
    "    snd = 0.5 * X / np.max(X)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    train = GetGSP(chirp, snd, index_sync, True, n=1)   # 実測の時はTrueを変える．\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_train.append(train)\n",
    "    y_train.append([[(i%61)/20, (i//61)/20] for _ in range(train.shape[0])])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.vstack(y_train)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 4800).astype(\"float32\")\n",
    "y_train = y_train.reshape(-1, 2).astype(\"float32\")\n",
    "\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=X_train, pos=y_train)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/train_4941.npz\").upload_fileobj(temp)\n",
    "\n",
    "# # 保存するのはX, posの2変数\n",
    "# np.savez(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/train_4941.npz\", X=X_train, pos=y_train)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_train[:, 0], y_train[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Training data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/train_4941.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29a41cd1-06a7-428b-bcb3-ccd38fab5c9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 測位用(25cmおき: データ数221)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "\n",
    "mic_loc = np.array([[], [], []])\n",
    "\n",
    "for i in range(13 * 17):\n",
    "    mic_loc = np.c_[mic_loc, [(i//13)/4 + 4.6, (i%13)/4 + 0.4, 1]]\n",
    "    \n",
    "room.add_microphone(mic_loc)\n",
    "\n",
    "_, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "# 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "# オプションで delay を追加することもできます。\n",
    "room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "# S/N 比\n",
    "SNR = 5\n",
    "\n",
    "#シミュレーション\n",
    "room.simulate(SNR)\n",
    "\n",
    "simulation_data = room.mic_array.signals\n",
    "\n",
    "for i in range(simulation_data.shape[0]):\n",
    "    \n",
    "    X = simulation_data[i]\n",
    "    snd = 0.5 * X / np.max(X)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    train = GetGSP(chirp, snd, index_sync, True, n=1)   # 実測の時はTrueを変える．\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_train.append(train)\n",
    "    y_train.append([[(i%13)/4, (i//13)/4] for _ in range(train.shape[0])])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.vstack(y_train)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 4800).astype(\"float32\")\n",
    "y_train = y_train.reshape(-1, 2).astype(\"float32\")\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=X_train, pos=y_train)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/train_221.npz\").upload_fileobj(temp)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_train[:, 0], y_train[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Training data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/train_221.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e4edd58-70d8-4da6-9c8c-3bb6a4c3c73f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (25cmおき: データ数165)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "pos_train = []\n",
    "\n",
    "for i in range(13*17):\n",
    "\n",
    "    # お部屋の形決め\n",
    "    room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "    #お部屋の素材決め\n",
    "    m = pra.make_materials(\n",
    "        ceiling=\"hard_surface\",\n",
    "        floor=\"linoleum_on_concrete\",\n",
    "        east=\"rough_concrete\",\n",
    "        west=\"rough_concrete\",\n",
    "        north=\"rough_concrete\",\n",
    "        south=\"blinds_half_open\",\n",
    "    )\n",
    "\n",
    "    room = pra.ShoeBox(\n",
    "        room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    "    )\n",
    "    mic_loc = np.array([[], [], []])\n",
    "\n",
    "    # 左右2点前後2点ヒントの距離ヒントの方向ヒントの座標\n",
    "    mic_loc = np.c_[mic_loc, [(i//13)/4 + 4.6, (i%13)/4 + 0.4, 1]]\n",
    "    room.add_microphone(mic_loc)\n",
    "\n",
    "    _, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "    # 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "    # オプションで delay を追加することもできます。\n",
    "    room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "    # S/N 比\n",
    "    SNR = 5\n",
    "\n",
    "    #シミュレーション\n",
    "    room.simulate(SNR)\n",
    "\n",
    "    simulation_data = room.mic_array.signals\n",
    "\n",
    "    \n",
    "    X1 = simulation_data[0]\n",
    "    snd1 = 0.5 * X1 / np.max(X1)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    train1 = GetGSP(chirp, snd1, index_sync, True, n=2)\n",
    "\n",
    "    # print(X_train.shape, train.shape)\n",
    "    for j in range(len(train1)):\n",
    "        X_train.append([train1[j]])\n",
    "        y_train.append([train1[j]])\n",
    "        pos_train.append([(i%13)/4, (i//13)/4])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_train = np.array(X_train).astype(\"float32\")\n",
    "y_train = np.array(y_train).astype(\"float32\")\n",
    "pos_train = np.array(pos_train).astype(\"float32\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"pos_train shape:\", pos_train.shape)\n",
    "\n",
    "# 保存するのはX, y, posの3変数\n",
    "np.savez(\"../data/train_2_data221.npz\", X=X_train, y=y_train, pos=pos_train)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pos_train[:, 0], pos_train[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Training data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"../data/fig/train_2_data221.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c528b1a-969c-4272-a408-5058631a3f49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9283614-6e87-45dc-9245-ef4797f3f722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 波形復元用(10cmおき: データ数1200)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "pos_train = []\n",
    "\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "mic_loc = np.array([[], [], []])\n",
    "\n",
    "# \n",
    "for i in range(30*40): \n",
    "    mic_loc = np.c_[mic_loc, [(i//30)/10 + 4.65, (i%30)/10 + 0.45, 1]]\n",
    "    \n",
    "room.add_microphone(mic_loc)\n",
    "\n",
    "_, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "# 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "# オプションで delay を追加することもできます。\n",
    "room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "# S/N 比\n",
    "SNR = 5\n",
    "\n",
    "#シミュレーション\n",
    "room.simulate(SNR)\n",
    "\n",
    "simulation_data = room.mic_array.signals\n",
    "\n",
    "for i in range(30*40):    \n",
    "    X = simulation_data[i]\n",
    "    snd = 0.5 * X / np.max(X)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    train1 = GetGSP(chirp, snd, index_sync, True, n=1)\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_train.append(train1)\n",
    "    y_train.append(train1)\n",
    "    pos_train.append([(i%30)/10+0.05, (i//30)/10+0.05])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_train = np.squeeze(X_train).astype(\"float32\")\n",
    "y_train = np.array(y_train).astype(\"float32\")\n",
    "pos_train = np.array(pos_train).astype(\"float32\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"pos_train shape:\", pos_train.shape)\n",
    "\n",
    "# 保存するのはX, y, posの3変数\n",
    "np.savez(\"../data/train_data1000.npz\", X=X_train, y=y_train, pos=pos_train)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pos_train[:, 0], pos_train[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Training data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"../data/fig/train_data1000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36670e3-b887-422f-9769-b4033472c06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Autoencoder用のデータ収集\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "pos_train = []\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "\n",
    "train_num = 100000\n",
    "np.random.seed(2025)\n",
    "x_pos = np.random.uniform(0, 4, train_num)\n",
    "y_pos = np.random.uniform(0, 3, train_num)\n",
    "\n",
    "for i in range(train_num):\n",
    "\n",
    "    # お部屋の形決め\n",
    "    room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "    #お部屋の素材決め\n",
    "    m = pra.make_materials(\n",
    "        ceiling=\"hard_surface\",\n",
    "        floor=\"linoleum_on_concrete\",\n",
    "        east=\"rough_concrete\",\n",
    "        west=\"rough_concrete\",\n",
    "        north=\"rough_concrete\",\n",
    "        south=\"blinds_half_open\",\n",
    "    )\n",
    "\n",
    "    room = pra.ShoeBox(\n",
    "        room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    "    )\n",
    "\n",
    "    mic_loc = np.array([[], [], []])\n",
    "    mic_loc = np.c_[mic_loc, [x_pos[i] + 4.6, y_pos[i] + 0.4, 1]]\n",
    "    room.add_microphone(mic_loc)\n",
    "\n",
    "    _, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "    # 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "    # オプションで delay を追加することもできます。\n",
    "    room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "    # S/N 比\n",
    "    SNR = 5\n",
    "\n",
    "    #シミュレーション\n",
    "    room.simulate(SNR)\n",
    "\n",
    "    simulation_data = room.mic_array.signals\n",
    "\n",
    "        \n",
    "    X1 = simulation_data[0]\n",
    "    snd1 = 0.5 * X1 / np.max(X1)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    train1 = GetGSP(chirp, snd1, index_sync, True, n=1)\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_train.append(train1)\n",
    "    y_train.append(train1)\n",
    "    pos_train.append([y_pos[i], x_pos[i]])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_train = np.array(X_train).astype(\"float32\")\n",
    "y_train = np.array(y_train).astype(\"float32\")\n",
    "pos_train = np.vstack(pos_train).astype(\"float32\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"pos_train shape:\", pos_train.shape)\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=X_train, pos=pos_train)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/train_random_100000.npz\").upload_fileobj(temp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pos_train[:, 0], pos_train[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"train data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/train_random_100000.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20a08934-b2de-481e-ba4d-075de25fdba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb77e010-960d-4509-ac14-3f1da3e3540c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# テストデータの作成(1ch)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "pos_test = []\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "\n",
    "mic_loc = np.array([[], [], []])\n",
    "\n",
    "test_num = 1000\n",
    "np.random.seed(2024)\n",
    "x_pos = np.random.uniform(0, 4, test_num)\n",
    "y_pos = np.random.uniform(0, 3, test_num)\n",
    "for i in range(test_num):\n",
    "    mic_loc = np.c_[mic_loc, [x_pos[i] + 4.6, y_pos[i] + 0.4, 1]]\n",
    "room.add_microphone(mic_loc)\n",
    "\n",
    "_, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "# 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "# オプションで delay を追加することもできます。\n",
    "room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "# S/N 比\n",
    "SNR = 5\n",
    "\n",
    "#シミュレーション\n",
    "room.simulate(SNR)\n",
    "\n",
    "simulation_data = room.mic_array.signals\n",
    "\n",
    "for i in range(simulation_data.shape[0]):\n",
    "    \n",
    "    X1 = simulation_data[i]\n",
    "    snd1 = 0.5 * X1 / np.max(X1)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    test1 = GetGSP(chirp, snd1, index_sync, True, n=1)\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_test.append(test1)\n",
    "    y_test.append(test1)\n",
    "    pos_test.append([y_pos[i], x_pos[i]])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_test = np.array(X_test).astype(\"float32\")\n",
    "y_test = np.array(y_test).astype(\"float32\")\n",
    "pos_test = np.vstack(pos_test).astype(\"float32\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"pos_test shape:\", pos_test.shape)\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=X_test, pos=pos_test)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/test_1000.npz\").upload_fileobj(temp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pos_test[:, 0], pos_test[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Test data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/test_1000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacd0b12-f05b-4a72-988a-a077ea6ca84f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# テストデータの作成(1ch), 480samples\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "pos_test = []\n",
    "\n",
    "# お部屋の形決め\n",
    "room_dim = [11.025, 3.7, 3.98]\n",
    "\n",
    "#お部屋の素材決め\n",
    "m = pra.make_materials(\n",
    "    ceiling=\"hard_surface\",\n",
    "    floor=\"linoleum_on_concrete\",\n",
    "    east=\"rough_concrete\",\n",
    "    west=\"rough_concrete\",\n",
    "    north=\"rough_concrete\",\n",
    "    south=\"blinds_half_open\",\n",
    ")\n",
    "\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=48000, materials=m, max_order=10, sigma2_awgn=0.3\n",
    ")\n",
    "\n",
    "mic_loc = np.array([[], [], []])\n",
    "\n",
    "test_num = 1000\n",
    "np.random.seed(2024)\n",
    "x_pos = np.random.uniform(0, 4, test_num)\n",
    "y_pos = np.random.uniform(0, 3, test_num)\n",
    "for i in range(test_num):\n",
    "    mic_loc = np.c_[mic_loc, [x_pos[i] + 4.6, y_pos[i] + 0.4, 1]]\n",
    "room.add_microphone(mic_loc)\n",
    "\n",
    "_, audio = wavfile.read(\"/dbfs/mnt/mnt_wg3-1/mita/wav/chirp16k_19k_1.25s.wav\") # S3に適した形に書き換え\n",
    "\n",
    "# 音源ごとに座標情報を与え、`room`に追加していきます。\n",
    "# オプションで delay を追加することもできます。\n",
    "room.add_source([3.6, 2.2, 2.29], signal=audio, delay=0.2, directivity=dir_obj)\n",
    "\n",
    "# S/N 比\n",
    "SNR = 5\n",
    "\n",
    "#シミュレーション\n",
    "room.simulate(SNR)\n",
    "\n",
    "simulation_data = room.mic_array.signals\n",
    "\n",
    "for i in range(simulation_data.shape[0]):\n",
    "    \n",
    "    X1 = simulation_data[i]\n",
    "    snd1 = 0.5 * X1 / np.max(X1)\n",
    "\n",
    "    chirp = ChirpMaker(16000, 19000, 0.02, 1)\n",
    "    index_sync = 0.2\n",
    "\n",
    "    test1 = GetGSP(chirp, snd1, index_sync, True, n=1)\n",
    "    \n",
    "    # print(X_train.shape, train.shape)\n",
    "    X_test.append(test1)\n",
    "    y_test.append(test1)\n",
    "    pos_test.append([y_pos[i], x_pos[i]])\n",
    "\n",
    "    print(\"\\r\"+f\"{i+1} samples have been processed.\",end=\"\")\n",
    "\n",
    "# 最後に numpy 配列に変換\n",
    "X_test = np.array(X_test).astype(\"float32\")\n",
    "y_test = np.array(y_test).astype(\"float32\")\n",
    "pos_test = np.vstack(pos_test).astype(\"float32\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"pos_test shape:\", pos_test.shape)\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=X_test, pos=pos_test)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/test_random_1000.npz\").upload_fileobj(temp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pos_test[:, 0], pos_test[:, 1], s=1)\n",
    "plt.scatter([1.8], [-1.0], color=\"black\", marker=\"*\", s=2, label=\"speaker\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Test data\")\n",
    "plt.xlim(-0.4, 3.3)\n",
    "plt.ylim(4.2, -1.2)\n",
    "plt.legend()\n",
    "plt.savefig(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/test_random_1000.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bf91cc7-86dd-4eb0-aec3-96dbcd01a754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0/1のデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a65e9ec-b808-4a1c-9b65-dc7a449c6224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/train_random_100000.npz\")\n",
    "X_train = data[\"X\"]\n",
    "pos_train = data[\"pos\"]\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    new = np.zeros((1, 480))\n",
    "    pak = np.array(PeakDetector(X_train[i].squeeze(), 2, 20, 1.6))\n",
    "    for j in pak[:, 0]:\n",
    "        new[0][int(j)] = 1\n",
    "    new_data.append(new)\n",
    "    print(f\"{i} samples has processed.\", end=\"\\r\")\n",
    "\n",
    "\n",
    "new_data = np.array(new_data)\n",
    "print(new_data.shape, pos_train.shape)\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=new_data, pos=pos_train)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/train_random_100000_peak.npz\").upload_fileobj(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c13f5c0-f92a-47e7-863d-7cf5e0c9ac5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/test_random_1000.npz\")\n",
    "X_test = data[\"X\"]\n",
    "pos_test = data[\"pos\"]\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    new = np.zeros((1, 480))\n",
    "    pak = np.array(PeakDetector(X_test[i].squeeze(), 2, 20, 1.6))\n",
    "    for j in pak[:, 0]:\n",
    "        new[0][int(j)] = 1\n",
    "    new_data.append(new)\n",
    "    print(f\"{i} samples has processed.\", end=\"\\r\")\n",
    "\n",
    "\n",
    "new_data = np.array(new_data)\n",
    "print(new_data.shape, pos_test.shape)\n",
    "\n",
    "# 保存するのはX, posの2変数\n",
    "with tempfile.TemporaryFile() as temp:\n",
    "    np.savez(temp, X=new_data, pos=pos_test)\n",
    "    temp.seek(0)\n",
    "    res = s3.Object(bucket_name=\"wg3-1\", key=\"mita/simulation_data/test_1000_peak.npz\").upload_fileobj(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d889de-d114-48b0-9e30-370f22167995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(\"/dbfs/mnt/mnt_wg3-1/mita/simulation_data/test_1000_peak.npz\")\n",
    "X = data[\"X\"]\n",
    "plt.plot(X[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acf1db9f-8c44-4a73-abb5-3b7cae89e2cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "prepare_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
